import os
import datetime as dt

import requests
import pandas as pd
from airflow.models import DAG
from airflow.operators.python import PythonOperator

args = {
    'owner': 'airflow',
    'start_date': dt.datetime(2020, 2, 11),
    'retries': 1,
    'retry_delay': dt.timedelta(minutes=1),
    'depends_on_past': False,
}

FILENAME = os.path.join(os.path.expanduser('~'), 'titanic.csv')

def download_titanic_dataset():
    url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'
    response = requests.get(url, stream=True)
    response.raise_for_status()
    with open(FILENAME, 'w', encoding='utf-8') as f:
        for chunk in response.iter_lines():
            f.write('{}\\n'.format(chunk.decode('utf-8')))

def pivot_dataset():
    titanic_df = pd.read_csv(FILENAME)
    pvt = titanic_df.pivot_table(
        index=['Sex'], columns=['Pclass'], values='Name', aggfunc='count'
    )
    df = pvt.reset_index()
    df.to_csv(os.path.join(os.path.expanduser('~'), 'titanic_pivot.csv'))

with DAG(dag_id='titanic_pivot', default_args=args, schedule=None) as dag:
    create_titanic_dataset = PythonOperator(
        task_id='download_titanic_dataset',
        python_callable=download_titanic_dataset,
        dag=dag
    )
    pivot_titanic_dataset = PythonOperator(
        task_id='pivot_dataset',
        python_callable=pivot_dataset,
        dag=dag
    )
    create_titanic_dataset >> pivot_titanic_dataset




from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import pickle
import pandas as pd
from sklearn.base import BaseEstimator
from sklearn.neighbors import KNeighborsClassifier  # Замени на свою библиотеку модели

MODEL_PATH = '/home/user1/Загрузки/Data/Data/test_model.pkl'
USER_DATA_PATH = '/home/user1/Загрузки/Data/Data/lolic.csv'
RETRAINED_MODEL_PATH = '/home/user1/Загрузки/Data/Data/test_new.pkl'

def retrain_model():
    # Загрузка модели из .pkl файла
    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)

    # Проверка, что модель поддерживает дообучение
    if not hasattr(model, 'partial_fit'):
        raise ValueError("Модель не поддерживает метод partial_fit для дообучения!")

    # Загрузка данных, загруженных пользователем
    user_data = pd.read_csv(USER_DATA_PATH)

    # Предположим, что данные уже предобработаны
    X_new = user_data.drop('target', axis=1)  # Признаки
    y_new = user_data['target']  # Целевая переменная

    model.partial_fit(X_new, y_new)  
    with open(RETRAINED_MODEL_PATH, 'wb') as f:
        pickle.dump(model, f)

    print("Модель успешно дообучена на пользовательских данных и сохранена!")

# Создание DAG
dag = DAG(
    'retrain_model_with_user_data_dag',
    description='DAG для дообучения модели на основе данных, загруженных пользователем',
    schedule=None,  #
    start_date=datetime(2025, 3, 1),
    catchup=False
)

retrain_task = PythonOperator(
    task_id='retrain_model_with_user_data_task',
    python_callable=retrain_model,
    dag=dag
)

retrain_task
